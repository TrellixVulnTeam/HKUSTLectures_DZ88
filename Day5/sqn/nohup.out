2019-04-23 06:25:17,949 [INFO ] main com.amazonaws.ml.mms.ModelServer - 
MMS Home: /Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages
Current directory: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn
Temp directory: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 4096 M
Python executable: /Users/cyrusmv/miniconda3/envs/production/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn
Initial Models: squeezenet_local=squeezenet_v1.1.mar
Log dir: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn/logs
Metrics dir: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-04-23 06:25:17,954 [INFO ] main com.amazonaws.ml.mms.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-04-23 06:25:18,003 [INFO ] main com.amazonaws.ml.mms.archive.ModelArchive - model folder already exists: 1e2a369d8f7b3d5c1e73830eda8283be0308ae50
2019-04-23 06:25:18,018 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model squeezenet_local loaded.
2019-04-23 06:25:18,018 [DEBUG] main com.amazonaws.ml.mms.wlm.ModelManager - updateModel: squeezenet_local, count: 4
2019-04-23 06:25:18,038 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-04-23 06:25:18,253 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-04-23 06:25:18,254 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-04-23 06:25:18,256 [INFO ] main com.amazonaws.ml.mms.ModelServer - Management API bind to: http://127.0.0.1:8081
Model server started.
2019-04-23 06:25:18,270 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.
2019-04-23 06:25:18,400 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:18,401 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43785
2019-04-23 06:25:18,403 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:18,404 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:25:18,407 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:18,409 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:18,410 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:18,413 [INFO ] pool-2-thread-1 MMS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971918
2019-04-23 06:25:18,413 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43786
2019-04-23 06:25:18,414 [INFO ] pool-2-thread-1 MMS_METRICS - DiskAvailable.Gigabytes:192.13327407836914|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971918
2019-04-23 06:25:18,414 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:18,414 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:25:18,415 [INFO ] pool-2-thread-1 MMS_METRICS - DiskUsage.Gigabytes:270.9371681213379|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971918
2019-04-23 06:25:18,415 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:18,415 [INFO ] pool-2-thread-1 MMS_METRICS - DiskUtilization.Percent:58.5|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971918
2019-04-23 06:25:18,415 [INFO ] pool-2-thread-1 MMS_METRICS - MemoryAvailable.Megabytes:6350.6484375|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971918
2019-04-23 06:25:18,416 [INFO ] pool-2-thread-1 MMS_METRICS - MemoryUsed.Megabytes:9225.83203125|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971918
2019-04-23 06:25:18,416 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:18,417 [INFO ] pool-2-thread-1 MMS_METRICS - MemoryUtilization.Percent:61.2|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971918
2019-04-23 06:25:18,426 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:25:18,432 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:25:18,432 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:18,433 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43787
2019-04-23 06:25:18,433 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:18,433 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:25:18,434 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:18,434 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:18,437 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:25:18,442 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:18,443 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43788
2019-04-23 06:25:18,443 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:18,443 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:25:18,443 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:18,443 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:18,447 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:25:20,611 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:20,611 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:20,611 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:20,612 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:20,612 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:20,613 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:20,613 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:20,613 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:20,613 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:20,613 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:20,614 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:20,614 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:20,614 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:20,614 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:20,614 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:20,614 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:20,614 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:20,615 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:20,615 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:20,615 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:20,615 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:20,615 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:20,615 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:20,616 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:20,618 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:20,618 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:20,616 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:20,619 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:20,618 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:20,620 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:20,620 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:20,620 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:20,621 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:20,621 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:20,622 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:20,622 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:20,624 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-04-23 06:25:20,625 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:20,625 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:20,625 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:20,626 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:20,627 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:20,627 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:20,648 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-04-23 06:25:20,695 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:20,695 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:20,695 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:20,696 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:20,696 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:20,696 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:20,696 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:20,697 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:20,697 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:20,697 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:20,697 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:20,697 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:20,698 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:20,698 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:20,698 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:20,698 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:20,698 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:20,698 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:20,699 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:20,699 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:20,700 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:20,700 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-04-23 06:25:20,718 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:20,718 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:20,718 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:20,718 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:20,718 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:20,718 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:20,719 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:20,719 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:20,719 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:20,719 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:20,720 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:20,720 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-04-23 06:25:20,720 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:20,720 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:20,720 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:20,720 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:20,721 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:20,721 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:20,721 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:20,721 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:20,721 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:20,721 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:21,797 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:21,798 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43844
2019-04-23 06:25:21,798 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:21,798 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:21,798 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:21,798 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:21,801 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:25:21,822 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:21,823 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43845
2019-04-23 06:25:21,824 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:21,824 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:21,827 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:21,827 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:21,830 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:25:21,906 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:21,907 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43846
2019-04-23 06:25:21,907 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:21,907 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:21,907 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:21,908 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:21,910 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:25:21,954 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:21,954 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43847
2019-04-23 06:25:21,955 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:21,955 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:21,955 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:21,955 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:21,960 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:25:24,190 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:24,190 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:24,191 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:24,191 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:24,191 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:24,191 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:24,191 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:24,191 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:24,191 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:24,192 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:24,192 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:24,192 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:24,192 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:24,192 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:24,194 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:24,195 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:24,195 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:24,195 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:24,195 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:24,195 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:24,195 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:24,197 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-04-23 06:25:24,223 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:24,224 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:24,224 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:24,224 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:24,224 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:24,224 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:24,225 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:24,225 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:24,225 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:24,225 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:24,225 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:24,225 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:24,225 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-04-23 06:25:24,225 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:24,226 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:24,281 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:24,281 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:24,281 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:24,281 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:24,281 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:24,281 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:24,282 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:24,282 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:24,282 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:24,282 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:24,282 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:24,282 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:24,282 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:24,283 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-04-23 06:25:24,283 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:24,283 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:24,283 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:24,283 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:24,283 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:24,284 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:24,284 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:24,284 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:24,318 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:24,318 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:24,319 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:24,319 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:24,319 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:24,319 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:24,319 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:24,319 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:24,319 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:24,319 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:24,320 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:24,321 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:24,321 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:24,321 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:24,321 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:25,409 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:25,411 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43873
2019-04-23 06:25:25,411 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:25,411 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:25,411 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:25,411 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:25,414 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:25:25,459 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:25,464 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43874
2019-04-23 06:25:25,465 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:25,465 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:25,465 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:25,465 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:25,466 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:25:25,556 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:25,557 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43875
2019-04-23 06:25:25,558 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:25,558 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:25,558 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:25,558 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:25,562 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:25:25,578 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:25,578 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43876
2019-04-23 06:25:25,578 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:25,579 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:25,579 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:25,579 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:25,580 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:25:27,576 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:27,577 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:27,577 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:27,577 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:27,577 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:27,577 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:27,577 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:27,578 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:27,578 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:27,578 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:27,578 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:27,578 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:27,578 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:27,578 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:27,578 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:27,578 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:27,579 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:27,579 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:27,579 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:27,579 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:27,579 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:27,579 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-04-23 06:25:27,602 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:27,602 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:27,603 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:27,604 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:27,604 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:27,604 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:27,604 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:27,604 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:27,604 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:27,605 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:27,605 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:27,605 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:27,606 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:27,606 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-04-23 06:25:27,637 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:27,637 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:27,637 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:27,637 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:27,637 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:27,637 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:27,638 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:27,638 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:27,638 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:27,639 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:27,639 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:27,639 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:27,639 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:27,639 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:27,639 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:27,647 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:27,648 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:27,648 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:27,648 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:27,648 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:27,648 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:27,648 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:27,648 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:27,648 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:27,649 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:27,649 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:27,649 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:27,649 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:27,649 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:27,649 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-04-23 06:25:27,649 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:27,649 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:27,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:27,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:27,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:27,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:27,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:29,776 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:29,776 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43892
2019-04-23 06:25:29,776 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:29,776 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:29,776 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:29,776 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:29,778 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:25:29,825 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:29,826 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43893
2019-04-23 06:25:29,826 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:29,826 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:29,826 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:29,826 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:29,828 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:25:29,873 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:29,873 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43894
2019-04-23 06:25:29,873 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:29,873 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:29,873 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:29,873 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:29,875 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:25:29,893 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:29,893 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43895
2019-04-23 06:25:29,893 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:29,893 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:29,893 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:29,893 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:29,896 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:25:31,891 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:31,891 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:31,891 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:31,892 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:31,892 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:31,892 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:31,892 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:31,892 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:31,892 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:31,892 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:31,892 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:31,892 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:31,892 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:31,893 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:31,918 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:31,918 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:31,918 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:31,919 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:31,919 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:31,919 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:31,919 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:31,919 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:31,919 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:31,919 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:31,919 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:31,919 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:31,919 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:31,919 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:31,920 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:31,930 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:31,930 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:31,930 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:31,930 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:31,931 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:31,932 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:31,932 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:31,933 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:31,934 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:31,934 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:31,934 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:31,970 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:31,971 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:31,971 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:31,971 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:31,971 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:31,971 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:31,971 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:31,971 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:31,971 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:31,971 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:31,971 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:31,972 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:31,972 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2019-04-23 06:25:35,081 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:35,082 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43913
2019-04-23 06:25:35,082 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:35,082 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:35,082 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:35,082 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:35,084 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:25:35,115 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:35,115 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43914
2019-04-23 06:25:35,116 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:35,116 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:35,116 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:35,116 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:35,118 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:25:35,155 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:35,155 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43915
2019-04-23 06:25:35,155 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:35,156 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:35,156 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:35,156 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:35,157 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:25:35,198 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:35,198 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43916
2019-04-23 06:25:35,198 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:35,198 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:35,198 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:35,198 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:35,200 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:25:37,105 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:37,105 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:37,105 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:37,105 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:37,105 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:37,105 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:37,106 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:37,106 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:37,107 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:37,107 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:37,107 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:37,107 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:37,107 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:37,107 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:37,108 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2019-04-23 06:25:37,155 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:37,155 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:37,155 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:37,155 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:37,156 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:37,156 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:37,156 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:37,156 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:37,156 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:37,156 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:37,157 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:37,157 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:37,157 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:37,157 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:37,157 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:37,157 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:37,157 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:37,158 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:37,158 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:37,158 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:37,158 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:37,158 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2019-04-23 06:25:37,217 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:37,218 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:37,218 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:37,219 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:37,218 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:37,219 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:37,219 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:37,219 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:37,219 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:37,219 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:37,219 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:37,219 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:37,220 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:37,220 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2019-04-23 06:25:37,271 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:37,271 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:37,271 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:37,271 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:37,272 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:37,272 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:37,272 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:37,273 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:37,273 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:37,273 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:37,273 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:37,273 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:37,273 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:37,273 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:37,273 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2019-04-23 06:25:42,303 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:42,304 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43933
2019-04-23 06:25:42,304 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:42,304 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:42,304 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:42,304 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:42,306 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:25:42,368 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:42,369 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43934
2019-04-23 06:25:42,369 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:42,369 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:42,369 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:42,369 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:42,370 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:25:42,446 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:42,446 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43935
2019-04-23 06:25:42,447 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:42,447 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:42,447 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:42,447 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:42,448 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:25:42,480 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:42,481 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43936
2019-04-23 06:25:42,481 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:42,481 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:42,481 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:42,481 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:42,482 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:25:44,505 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:44,505 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:44,505 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:44,505 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:44,506 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:44,506 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:44,506 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:44,506 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:44,506 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:44,506 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:44,506 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:44,506 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:44,507 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:44,507 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2019-04-23 06:25:44,507 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:44,536 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:44,536 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:44,536 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:44,536 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:44,536 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:44,536 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:44,537 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:44,537 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:44,537 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:44,537 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:44,538 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:44,538 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:44,538 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:44,539 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2019-04-23 06:25:44,598 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:44,598 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:44,598 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:44,598 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:44,598 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:44,598 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:44,598 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:44,598 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:44,598 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:44,599 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:44,599 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:44,599 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:44,599 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:44,599 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:44,599 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:44,599 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2019-04-23 06:25:44,599 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:44,599 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:44,600 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:44,600 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:44,600 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:44,600 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:44,616 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:44,616 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:44,617 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:44,617 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:44,617 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:44,617 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:44,617 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:44,617 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:44,617 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:44,618 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:44,618 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:44,618 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:44,618 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:44,618 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:44,618 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:44,618 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:44,618 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:44,619 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:44,619 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:44,619 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:44,619 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:44,619 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2019-04-23 06:25:52,667 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:52,668 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43952
2019-04-23 06:25:52,668 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:52,668 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:52,668 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:52,668 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:25:52,670 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:25:52,723 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:52,723 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43953
2019-04-23 06:25:52,724 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:52,724 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:52,724 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:52,724 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:25:52,725 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:25:52,818 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:52,819 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43954
2019-04-23 06:25:52,819 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:52,819 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:52,819 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:52,819 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:25:52,820 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:25:52,845 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:52,846 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43955
2019-04-23 06:25:52,846 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:25:52,847 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:25:52,847 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:25:52,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:25:52,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:54,724 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:54,725 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:54,725 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:54,725 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:54,725 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:54,725 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:54,725 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:54,725 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:54,725 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:54,725 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:54,725 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:54,725 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:54,726 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:54,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:54,736 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:54,736 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:54,736 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:54,736 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:54,736 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:54,736 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:54,736 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:54,737 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:54,737 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:54,737 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:54,737 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:54,738 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:54,838 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:54,838 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:54,839 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:54,839 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:54,839 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:54,839 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:54,839 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:54,839 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:54,839 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:54,839 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:54,839 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:54,840 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:25:54,849 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:25:54,850 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:25:54,850 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:25:54,851 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:25:54,851 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:25:54,851 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:25:54,852 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2019-04-23 06:26:07,945 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:26:07,950 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:26:07,953 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43975
2019-04-23 06:26:07,953 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43974
2019-04-23 06:26:07,966 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:07,966 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:07,966 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:07,966 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:07,975 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:07,976 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:26:07,975 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:07,976 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:26:07,985 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:26:07,986 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:26:08,073 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:26:08,077 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43977
2019-04-23 06:26:08,078 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:08,078 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:08,089 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:26:08,089 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:08,091 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:26:08,103 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:26:08,115 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]43976
2019-04-23 06:26:08,122 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:08,122 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:08,130 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:08,130 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:26:08,141 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:26:10,599 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:10,599 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:10,599 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:10,599 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:10,599 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:10,599 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:10,599 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:10,599 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:10,600 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:10,600 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:10,600 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:10,600 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:10,600 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:10,600 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:10,600 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:10,600 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:10,601 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:10,601 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2019-04-23 06:26:10,601 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:10,601 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:10,601 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:10,601 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:10,649 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:10,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:10,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:10,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:10,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:10,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:10,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:10,650 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:10,651 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:10,651 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:10,651 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:10,651 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:10,651 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:10,651 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:10,651 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:10,651 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:10,652 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:10,652 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:10,652 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:10,652 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:10,652 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:10,652 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2019-04-23 06:26:10,679 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:10,679 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:10,679 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:10,679 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:10,680 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:10,680 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:10,680 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:10,680 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:10,680 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:10,680 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:10,680 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:10,680 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:10,680 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:10,681 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:10,765 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:10,765 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:10,765 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:10,766 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:10,766 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:10,766 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:10,766 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:10,766 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:10,766 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:10,766 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:10,766 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:10,767 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:10,767 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2019-04-23 06:26:10,767 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:18,389 [INFO ] pool-2-thread-2 MMS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971978
2019-04-23 06:26:18,389 [INFO ] pool-2-thread-2 MMS_METRICS - DiskAvailable.Gigabytes:192.1310691833496|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971978
2019-04-23 06:26:18,390 [INFO ] pool-2-thread-2 MMS_METRICS - DiskUsage.Gigabytes:270.9393730163574|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971978
2019-04-23 06:26:18,390 [INFO ] pool-2-thread-2 MMS_METRICS - DiskUtilization.Percent:58.5|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971978
2019-04-23 06:26:18,390 [INFO ] pool-2-thread-2 MMS_METRICS - MemoryAvailable.Megabytes:6246.25|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971978
2019-04-23 06:26:18,390 [INFO ] pool-2-thread-2 MMS_METRICS - MemoryUsed.Megabytes:9333.1015625|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971978
2019-04-23 06:26:18,391 [INFO ] pool-2-thread-2 MMS_METRICS - MemoryUtilization.Percent:61.9|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555971978
2019-04-23 06:26:18,409 [ERROR] Thread-2 com.amazonaws.ml.mms.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_common.py", line 341, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 339, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_common.py", line 344, in wrapper
    return fun(self)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 391, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 469, in _init
    self.create_time()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 819, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 339, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 494, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 342, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=43975)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 28, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 442, in __init__
    self._init(pid)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 482, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 43975

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "mms/metrics/metric_collector.py", line 26, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 48, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 30, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('43975',)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "mms/metrics/metric_collector.py", line 26, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 48, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('43975', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_common.py", line 341, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 339, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_common.py", line 344, in wrapper
    return fun(self)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 391, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 469, in _init
    self.create_time()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 819, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 339, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 494, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 342, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=43976)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 28, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 442, in __init__
    self._init(pid)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 482, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 43976

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "mms/metrics/metric_collector.py", line 26, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 48, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 30, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('43976',)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "mms/metrics/metric_collector.py", line 26, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 48, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('43976', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_common.py", line 341, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 339, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_common.py", line 344, in wrapper
    return fun(self)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 391, in _get_kinfo_proc
    ret = cext.proc_kinfo_oneshot(self.pid)
ProcessLookupError: [Errno 3] No such process

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 469, in _init
    self.create_time()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 819, in create_time
    self._create_time = self._proc.create_time()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 339, in wrapper
    return fun(self, *args, **kwargs)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 494, in create_time
    return self._get_kinfo_proc()[kinfo_proc_map['ctime']]
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/_psosx.py", line 342, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=43977)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 28, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 442, in __init__
    self._init(pid)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/psutil/__init__.py", line 482, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 43977

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "mms/metrics/metric_collector.py", line 26, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 48, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 30, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('43977',)
--- Logging error ---
Traceback (most recent call last):
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 998, in emit
    self.flush()
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/logging/__init__.py", line 978, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "mms/metrics/metric_collector.py", line 26, in <module>
    check_process_mem_usage(sys.stdin)
  File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/metrics/process_memory_metric.py", line 48, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('43977', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='US-ASCII'>
BrokenPipeError: [Errno 32] Broken pipe

2019-04-23 06:26:31,758 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:26:31,759 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44038
2019-04-23 06:26:31,759 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:31,759 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:31,759 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:31,759 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:26:31,760 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:26:31,856 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:26:31,857 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44039
2019-04-23 06:26:31,857 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:31,857 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:31,857 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:31,857 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:26:31,858 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:26:31,959 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:26:31,961 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44040
2019-04-23 06:26:31,961 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:31,961 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:31,961 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:31,961 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:26:31,971 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:26:32,108 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:26:32,108 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44042
2019-04-23 06:26:32,109 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:26:32,109 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:26:32,109 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:26:32,109 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:26:32,111 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:26:34,146 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:34,146 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:34,146 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:34,147 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:34,148 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:34,150 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:34,150 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:34,151 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:34,151 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:34,152 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2019-04-23 06:26:34,160 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:34,160 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:34,160 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:34,160 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:34,160 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:34,160 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:34,161 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:34,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:34,162 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:34,162 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:34,162 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:34,162 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:34,162 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:34,162 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:34,162 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2019-04-23 06:26:34,213 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:34,213 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:34,213 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:34,214 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:34,214 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:34,215 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:34,215 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:34,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:34,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:34,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:34,216 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2019-04-23 06:26:34,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:34,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:34,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:34,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:34,246 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:26:34,247 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:26:34,247 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:26:34,247 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:26:34,248 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:26:34,248 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:26:34,248 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:26:34,248 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:26:34,248 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:26:34,248 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:26:34,248 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:26:34,248 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:26:34,249 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2019-04-23 06:26:44,558 [INFO ] W-9003-squeezenet_local ACCESS_LOG - /127.0.0.1:58954 "GET /ping HTTP/1.1" 200 8
2019-04-23 06:26:44,558 [INFO ] W-9003-squeezenet_local MMS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:null
2019-04-23 06:27:26,290 [INFO ] main com.amazonaws.ml.mms.ModelServer - 
MMS Home: /Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages
Current directory: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn
Temp directory: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 4096 M
Python executable: /Users/cyrusmv/miniconda3/envs/production/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Model Store: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn
Initial Models: squeezenet_local=squeezenet_v1.1.mar
Log dir: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn/logs
Metrics dir: /Users/cyrusmv/PycharmProjects/HKUSTLectures/Day5/sqn/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
2019-04-23 06:27:26,295 [INFO ] main com.amazonaws.ml.mms.ModelServer - Loading initial models: squeezenet_v1.1.mar
2019-04-23 06:27:26,343 [INFO ] main com.amazonaws.ml.mms.archive.ModelArchive - model folder already exists: 1e2a369d8f7b3d5c1e73830eda8283be0308ae50
2019-04-23 06:27:26,357 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model squeezenet_local loaded.
2019-04-23 06:27:26,358 [DEBUG] main com.amazonaws.ml.mms.wlm.ModelManager - updateModel: squeezenet_local, count: 4
2019-04-23 06:27:26,535 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2019-04-23 06:27:26,635 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:26,638 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44089
2019-04-23 06:27:26,638 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:26,639 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:26,640 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44092
2019-04-23 06:27:26,640 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:26,640 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:26,640 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:26,641 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:27:26,641 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:27:26,646 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:26,646 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:26,654 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:26,655 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44090
2019-04-23 06:27:26,655 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:26,655 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:27:26,655 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:26,655 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:26,700 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:26,701 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44091
2019-04-23 06:27:26,702 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:26,702 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change null -> WORKER_STARTED
2019-04-23 06:27:26,702 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:26,702 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:26,729 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:27:26,730 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:27:26,731 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://127.0.0.1:8080
2019-04-23 06:27:26,732 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:27:26,732 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2019-04-23 06:27:26,735 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:27:26,736 [INFO ] main com.amazonaws.ml.mms.ModelServer - Management API bind to: http://127.0.0.1:8081
Model server started.
2019-04-23 06:27:26,898 [INFO ] pool-2-thread-1 MMS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555972046
2019-04-23 06:27:26,899 [INFO ] pool-2-thread-1 MMS_METRICS - DiskAvailable.Gigabytes:192.12700271606445|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555972046
2019-04-23 06:27:26,899 [INFO ] pool-2-thread-1 MMS_METRICS - DiskUsage.Gigabytes:270.9434394836426|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555972046
2019-04-23 06:27:26,900 [INFO ] pool-2-thread-1 MMS_METRICS - DiskUtilization.Percent:58.5|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555972046
2019-04-23 06:27:26,900 [INFO ] pool-2-thread-1 MMS_METRICS - MemoryAvailable.Megabytes:6271.63671875|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555972046
2019-04-23 06:27:26,900 [INFO ] pool-2-thread-1 MMS_METRICS - MemoryUsed.Megabytes:9308.84765625|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555972046
2019-04-23 06:27:26,901 [INFO ] pool-2-thread-1 MMS_METRICS - MemoryUtilization.Percent:61.7|#Level:Host|#hostname:4c3275961cd1.ant.amazon.com,timestamp:1555972046
2019-04-23 06:27:29,696 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:29,696 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:29,697 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:29,697 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:29,697 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:29,697 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:29,698 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:29,698 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:29,698 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:29,698 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:29,699 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:29,699 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:29,699 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:29,706 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:29,706 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:29,707 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:29,707 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:29,707 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:29,708 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:29,711 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:29,711 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:29,713 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-04-23 06:27:29,732 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:29,732 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:29,732 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:29,733 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:29,733 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:29,733 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:29,733 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:29,733 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:29,734 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:29,734 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:29,734 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:29,735 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:29,735 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:29,735 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:29,736 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:29,736 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:29,736 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:29,736 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:29,736 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:29,736 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:29,736 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:29,737 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-04-23 06:27:29,746 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:29,747 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:29,747 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:29,747 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:29,747 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:29,747 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:29,747 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:29,748 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:29,748 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:29,748 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:29,748 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:29,749 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:29,749 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:29,749 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:29,749 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:29,749 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:29,749 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:29,759 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:29,759 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:29,760 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:29,761 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:29,761 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-04-23 06:27:29,884 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:29,884 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:29,885 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:29,885 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:29,885 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:29,885 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:29,885 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:29,886 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:29,886 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:29,886 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:29,886 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:29,886 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:29,886 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:29,887 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:29,887 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:29,887 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:29,887 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:29,887 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:29,887 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:29,888 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:29,888 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:29,889 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-04-23 06:27:30,915 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:30,915 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44108
2019-04-23 06:27:30,915 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:30,915 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:30,916 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:30,916 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:30,919 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:27:30,961 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:30,962 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44109
2019-04-23 06:27:30,962 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:30,962 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:30,963 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:30,965 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:30,968 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:27:31,037 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:31,037 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44110
2019-04-23 06:27:31,037 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:31,038 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:31,038 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:31,038 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:31,044 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:27:31,196 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:31,196 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44111
2019-04-23 06:27:31,196 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:31,197 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:31,197 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:31,197 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:31,199 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:27:33,476 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:33,477 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:33,479 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:33,479 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:33,479 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:33,479 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:33,480 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:33,480 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:33,480 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:33,480 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:33,480 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:33,480 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2019-04-23 06:27:33,480 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:33,481 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:33,481 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:33,481 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:33,481 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:33,482 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:33,482 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:33,482 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:33,482 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:33,482 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:33,495 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:33,496 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:33,496 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:33,496 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:33,496 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:33,498 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:33,498 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:33,498 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:33,498 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:33,499 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:33,499 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:33,499 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:33,499 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:33,499 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:33,499 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:33,499 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:33,500 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:33,500 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:33,500 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:33,500 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:33,500 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:33,502 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2019-04-23 06:27:33,537 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:33,538 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:33,538 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:33,538 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:33,538 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:33,538 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:33,538 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:33,538 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:33,539 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:33,539 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:33,539 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:33,539 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:33,539 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:33,539 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:33,539 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2019-04-23 06:27:33,539 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:33,539 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:33,540 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:33,540 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:33,540 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:33,540 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:33,540 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:33,604 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:33,604 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:33,604 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:33,604 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:33,605 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:33,605 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:33,605 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:33,605 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:33,605 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:33,605 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:33,605 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:33,606 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:33,606 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2019-04-23 06:27:33,606 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:33,607 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:34,662 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:34,662 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44124
2019-04-23 06:27:34,663 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:34,663 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:34,663 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:34,663 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:34,669 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:27:34,688 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:34,689 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44125
2019-04-23 06:27:34,689 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:34,689 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:34,689 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:34,690 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:34,698 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:27:34,754 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:34,762 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44126
2019-04-23 06:27:34,762 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:34,762 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:34,762 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:34,762 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:34,764 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:27:34,854 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:34,855 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44127
2019-04-23 06:27:34,856 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:34,856 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:34,856 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:34,856 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:34,859 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:27:36,749 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:36,750 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:36,750 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:36,750 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:36,751 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:36,751 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:36,751 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:36,751 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:36,751 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:36,751 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:36,751 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:36,752 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:36,753 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:36,753 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:36,753 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:36,805 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:36,805 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:36,805 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:36,805 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:36,806 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:36,806 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:36,806 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:36,806 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:36,806 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:36,806 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:36,806 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:36,806 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:36,806 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:36,807 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:36,809 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2019-04-23 06:27:36,843 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:36,843 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:36,844 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:36,844 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:36,844 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:36,844 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:36,844 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:36,844 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:36,844 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:36,845 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:36,845 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:36,846 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:36,846 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:36,846 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:36,931 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:36,931 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:36,931 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:36,931 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:36,932 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:36,932 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:36,932 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:36,932 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:36,932 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:36,932 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:36,932 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:36,932 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:36,933 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:38,918 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:38,918 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44144
2019-04-23 06:27:38,918 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:38,919 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:38,919 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:38,920 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:38,929 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:27:39,037 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:39,037 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44145
2019-04-23 06:27:39,037 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:39,037 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:39,037 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:39,038 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:39,039 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:27:39,086 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:39,086 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44146
2019-04-23 06:27:39,087 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:39,087 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:39,087 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:39,089 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:39,089 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:27:39,214 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:39,215 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44147
2019-04-23 06:27:39,215 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:39,215 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:39,216 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:39,217 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:39,218 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:27:41,490 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:41,490 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:41,490 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:41,490 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:41,490 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:41,490 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:41,491 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:41,491 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:41,491 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:41,491 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:41,491 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:41,491 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:41,491 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:41,491 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:41,491 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:41,492 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:41,492 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:41,492 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:41,492 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:41,492 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:41,492 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:41,492 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2019-04-23 06:27:41,538 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:41,539 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:41,539 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:41,539 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:41,539 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:41,539 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:41,539 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:41,539 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:41,539 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:41,540 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:41,540 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2019-04-23 06:27:41,595 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:41,595 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:41,595 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:41,596 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:41,596 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:41,597 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:41,597 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:41,597 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:41,597 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:41,597 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:41,597 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:41,597 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:41,598 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2019-04-23 06:27:41,669 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:41,670 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:41,670 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:41,670 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:41,670 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:41,670 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:41,670 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:41,670 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:41,670 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:41,671 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:41,671 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:41,671 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:41,671 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:41,671 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:41,671 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:41,671 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:41,671 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2019-04-23 06:27:41,671 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:41,672 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:41,672 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:41,672 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:41,672 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:44,634 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:44,635 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44160
2019-04-23 06:27:44,635 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:44,635 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:44,635 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:44,635 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:44,637 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:27:44,711 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:44,712 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44161
2019-04-23 06:27:44,713 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:44,713 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:44,713 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:44,716 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:44,716 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:27:44,822 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:44,822 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44162
2019-04-23 06:27:44,822 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:44,822 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:44,822 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:44,825 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:44,826 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:27:44,936 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:44,937 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44163
2019-04-23 06:27:44,937 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:44,937 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:44,937 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:44,937 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:44,939 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:27:46,692 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:46,692 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:46,692 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:46,692 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:46,692 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:46,692 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:46,692 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:46,693 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:46,693 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:46,693 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:46,693 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:46,693 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:46,693 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:46,693 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:46,694 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:46,694 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:46,694 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:46,694 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:46,694 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:46,694 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:46,694 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:46,695 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2019-04-23 06:27:46,827 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:46,827 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:46,828 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:46,828 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:46,828 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:46,828 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:46,829 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:46,829 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2019-04-23 06:27:46,829 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:46,830 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:46,830 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:46,830 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:46,830 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:46,830 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:46,866 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:46,866 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:46,866 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:46,866 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:46,866 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:46,867 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:46,867 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:46,867 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:46,868 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:46,868 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:46,868 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:46,868 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:46,868 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:46,868 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:46,869 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2019-04-23 06:27:46,911 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:46,911 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:46,911 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:46,911 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:46,912 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:46,912 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:46,912 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:46,912 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:46,914 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:46,914 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:46,914 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:46,915 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:46,915 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:51,820 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:51,820 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44179
2019-04-23 06:27:51,820 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:51,820 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:51,820 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:51,820 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:27:51,821 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:27:52,023 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:52,023 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44180
2019-04-23 06:27:52,023 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:52,024 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:52,024 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:52,024 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:27:52,025 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:27:52,092 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:52,093 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44181
2019-04-23 06:27:52,093 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:52,093 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:52,093 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:52,093 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:27:52,094 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:27:52,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:52,161 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44182
2019-04-23 06:27:52,162 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:27:52,162 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:27:52,162 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:27:52,162 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:27:52,163 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:27:54,008 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:54,008 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:54,008 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:54,009 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:54,010 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:54,010 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:54,011 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:54,011 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:54,011 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2019-04-23 06:27:54,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:54,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:54,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:54,214 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:54,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:54,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:54,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:54,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:54,215 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:54,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:54,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:54,215 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:54,215 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:54,215 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:54,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:54,216 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:54,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:54,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:54,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:54,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:54,216 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:54,216 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2019-04-23 06:27:54,261 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:54,261 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:54,261 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:54,261 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:54,261 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:54,261 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:54,262 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:54,262 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:54,262 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:54,262 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:54,262 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:54,262 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:54,262 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:54,262 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:54,262 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:54,262 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:54,263 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:54,263 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:54,263 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:54,263 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:54,263 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:54,263 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:27:54,308 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:27:54,309 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:27:54,309 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:27:54,309 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:27:54,309 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:27:54,309 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:27:54,309 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:27:54,309 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:27:54,310 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:27:54,310 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:27:54,310 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:27:54,310 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:27:54,310 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2019-04-23 06:28:02,182 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:28:02,182 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44201
2019-04-23 06:28:02,182 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:02,182 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:02,182 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:02,182 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:28:02,183 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:28:02,517 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:28:02,517 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44202
2019-04-23 06:28:02,517 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:02,517 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:02,517 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:02,518 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:28:02,519 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:28:02,523 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:28:02,523 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44203
2019-04-23 06:28:02,524 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:02,524 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:02,524 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:28:02,526 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:02,526 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:28:02,534 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:28:02,534 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44204
2019-04-23 06:28:02,536 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:02,536 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:02,536 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:28:02,541 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:02,541 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:28:04,831 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:04,831 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:04,831 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:04,831 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:04,831 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:04,831 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:04,831 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:04,832 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:04,832 [INFO ] KQueueEventLoopGroup-4-4 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:04,832 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:04,832 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:04,832 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:04,832 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:04,832 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:04,832 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:04,832 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:04,832 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:04,833 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:04,833 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:04,833 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:04,833 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:04,833 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2019-04-23 06:28:04,992 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:04,993 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:04,993 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:04,993 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:04,993 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:04,993 [INFO ] KQueueEventLoopGroup-4-2 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:04,993 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:04,993 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:04,993 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:04,993 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:04,993 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:04,994 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:04,994 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:05,037 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:05,037 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:05,038 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:05,038 [INFO ] KQueueEventLoopGroup-4-3 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:05,038 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:05,038 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:05,038 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:05,038 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:05,038 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:05,038 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:05,039 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:05,039 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:05,040 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:05,055 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:05,055 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:05,055 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:05,055 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:05,055 [INFO ] KQueueEventLoopGroup-4-1 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:05,055 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:05,056 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:05,056 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:05,056 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:05,056 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:05,056 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:05,056 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:05,057 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:05,058 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:17,977 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:28:17,978 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44269
2019-04-23 06:28:17,978 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:17,978 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:17,978 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:17,979 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003
2019-04-23 06:28:17,980 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9003.
2019-04-23 06:28:18,185 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:28:18,186 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44270
2019-04-23 06:28:18,186 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:18,186 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:18,186 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:18,186 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000
2019-04-23 06:28:18,187 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9000.
2019-04-23 06:28:18,264 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:28:18,264 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44271
2019-04-23 06:28:18,264 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:18,265 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:18,265 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:18,265 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002
2019-04-23 06:28:18,267 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9002.
2019-04-23 06:28:18,277 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:28:18,278 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]44272
2019-04-23 06:28:18,278 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.
2019-04-23 06:28:18,278 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STOPPED -> WORKER_STARTED
2019-04-23 06:28:18,278 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8
2019-04-23 06:28:18,278 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001
2019-04-23 06:28:18,279 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T//.mms.sock.9001.
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:19,991 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:19,992 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:19,992 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:19,992 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:19,992 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:19,992 [INFO ] W-9003-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:19,993 [INFO ] KQueueEventLoopGroup-4-5 com.amazonaws.ml.mms.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:19,993 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:19,993 [WARN ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:19,994 [DEBUG] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9003-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:19,994 [INFO ] W-9003-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2019-04-23 06:28:20,227 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:20,227 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:20,227 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:20,227 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:20,228 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:20,228 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:20,228 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:20,228 [INFO ] KQueueEventLoopGroup-4-6 com.amazonaws.ml.mms.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:20,228 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:20,228 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:20,228 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:20,229 [WARN ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:20,229 [DEBUG] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9000-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:20,229 [INFO ] W-9000-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2019-04-23 06:28:20,274 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:20,274 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:20,274 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:20,274 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:20,274 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:20,275 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:20,275 [INFO ] KQueueEventLoopGroup-4-8 com.amazonaws.ml.mms.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:20,275 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:20,275 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:20,275 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:20,275 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:20,275 [WARN ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:20,275 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:20,275 [DEBUG] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9001-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:20,276 [INFO ] W-9001-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:20,291 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Backend worker process die.
2019-04-23 06:28:20,291 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Traceback (most recent call last):
2019-04-23 06:28:20,291 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 172, in <module>
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     worker.run_server()
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 150, in run_server
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 116, in handle_connection
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_service_worker.py", line 96, in load_model
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2019-04-23 06:28:20,292 [INFO ] KQueueEventLoopGroup-4-7 com.amazonaws.ml.mms.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/Users/cyrusmv/miniconda3/envs/production/lib/python3.6/site-packages/mms/model_loader.py", line 127, in load
2019-04-23 06:28:20,292 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2019-04-23 06:28:20,293 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_vision_service.py", line 84, in handle
2019-04-23 06:28:20,293 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     _service.initialize(context)
2019-04-23 06:28:20,293 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   File "/private/var/folders/5m/ndw__g157hlf244bhdyqgv68pknqj9/T/models/1e2a369d8f7b3d5c1e73830eda8283be0308ae50/mxnet_model_service.py", line 59, in initialize
2019-04-23 06:28:20,293 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle -     raise RuntimeError("Missing signature.json file.")
2019-04-23 06:28:20,293 [INFO ] W-9002-squeezenet_local-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - RuntimeError: Missing signature.json file.
2019-04-23 06:28:20,293 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2050)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2127)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at com.amazonaws.ml.mms.wlm.WorkerThread.run(WorkerThread.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1135)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:844)
2019-04-23 06:28:20,293 [WARN ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.BatchAggregator - Load model failed: squeezenet_local, error: Worker died.
2019-04-23 06:28:20,293 [DEBUG] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - W-9002-squeezenet_local State change WORKER_STARTED -> WORKER_STOPPED
2019-04-23 06:28:20,301 [INFO ] W-9002-squeezenet_local com.amazonaws.ml.mms.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
